{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# SIMCODE simulation example - google colab compatible notebook\n",
        "\n",
        "This notebook downloads the required files to run SIMCODE and a conventional ROI fitting SMLM pipeline. It generates movie of simulated microtubules, including patterned illumination, and then generates the reconstructions.\n",
        "\n",
        "Note: Sometimes after editing code colab starts to complain about wrong locales. I've found the only way to fix it is to restart the whole runtime. Please let me know if you find a better way."
      ],
      "metadata": {
        "id": "hmH0Cy9B-vnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if there is a GPU\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "aD7XqcmUBSZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the SIMCODE source code\n",
        "%cd /content\n",
        "!git clone https://github.com/jcnossen/simcode.git\n",
        "%cd /content/simcode/\n",
        "!pip install -e .\n",
        "\n",
        "!cp /content/simcode/notebooks/generate_tubules.py /content/\n",
        "%cd /content\n",
        "# Google colab now requires either this, or restarting the runtime after doing a local package install\n",
        "import site\n",
        "site.main()\n"
      ],
      "metadata": {
        "id": "voVqLFZbIHYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the files for our conventional SMLM fitting pipeline (FastPSF)\n",
        "%cd /content/\n",
        "!rm -rf /content/fastpsf\n",
        "\n",
        "import urllib.request\n",
        "import os\n",
        "from IPython.utils import io\n",
        "\n",
        "if not os.path.exists(\"/content/fastpsf\"):\n",
        "  print(\"Unzipping SMLM PSF fitter...\")\n",
        "\n",
        "  binary_zip = '/content/simcode/notebooks/fastpsf-colab-binary.zip'\n",
        "  if not os.path.exists(binary_zip):\n",
        "    print(f'{binary_zip} not found. Building from source')\n",
        "\n",
        "    # compile from source (but cuda builds are slow)\n",
        "    %cd /content\n",
        "    !git clone https://gitlab.com/jcnossen/fastpsf.git\n",
        "    %cd /content/fastpsf\n",
        "    !cmake .\n",
        "    !make clean & make\n",
        "\n",
        "  else:\n",
        "    with io.capture_output() as captured:\n",
        "      !unzip -o {binary_zip} -d /content/\n"
      ],
      "metadata": {
        "id": "iszOJd9xY0hx",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/fastpsf/python\n",
        "%pip install -e .\n",
        "# Google colab now requires either this, or restarting the runtime after doing a local package install\n",
        "import site\n",
        "site.main()\n"
      ],
      "metadata": {
        "id": "_Rr1O_qOdDxA",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simcode_model_zip = '/content/simcode/model/model_weights_sf_conv_g1.3_tio2_L64_2.zip'\n",
        "simcode_model_path = '/content/simcode/model/sf_conv_g1.3_tio2_L64_2/'\n",
        "\n",
        "!unzip -o {simcode_model_zip} -d /content/simcode/model/"
      ],
      "metadata": {
        "id": "5lRrFTT0Y-9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eF-M0wyIASW"
      },
      "outputs": [],
      "source": [
        "import smlmtorch.simflux.pattern_estimator as pe\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from smlmtorch.util.multipart_tiff  import MultipartTiffSaver, tiff_read_all\n",
        "from smlmtorch import Dataset\n",
        "from smlmtorch.simflux.simulate import simulate, angles_to_mod\n",
        "from smlmtorch.simflux.localizer import SFLocalizer\n",
        "import tqdm\n",
        "from smlmtorch.simflux.localizer_report import LocalizationReporter\n",
        "from fastpsf import Context, GaussianPSFMethods\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from generate_tubules import generate_microtubule_points\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from IPython.utils import io\n",
        "\n",
        "np.random.seed(2)\n",
        "W = 50\n",
        "pixelsize = 100 #nm\n",
        "\n",
        "with io.capture_output() as captured: # suppress outputs\n",
        "  pts = generate_microtubule_points(  W, depth=0, numtubules = 20, spl_knots=5,\n",
        "                  linedensity=10, nudge_factor=0.1, margin=0.05, spl_degree=2)\n",
        "\n",
        "  gt_ds = Dataset(len(pts), 2, [W,W], pixelsize=pixelsize)\n",
        "  gt_ds.pos = pts[:,:2]\n",
        "  gt_ds.save('/content/ground-truth-points.hdf5')\n",
        "\n",
        "plt.figure();\n",
        "plt.scatter(pts[:,0],pts[:,1],s=1);\n",
        "# invert bottom/top to match imshow\n",
        "plt.gca().invert_yaxis();\n",
        "plt.xlabel('Pixels'); plt.ylabel('Pixels');\n",
        "plt.title(\"Simulated microtubules - ground truth\")\n"
      ],
      "metadata": {
        "id": "ukx0Lg8KcqdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulate an SMLM recording with modulated illumination\n",
        "on_fraction = 0.005 # controls density\n",
        "avg_on_time = 6\n",
        "nframes = 30000\n",
        "intensity = 500\n",
        "psf_sigma = 1.3\n",
        "psf_calib = [psf_sigma, psf_sigma] # XY\n",
        "\n",
        "background = 4 # approximately dna paint background on our dmd setup\n",
        "path = '/content/movie.tif'\n",
        "\n",
        "pixelsize = 100\n",
        "pattern_frames = np.array([  # Defines which frame indices have which modulation pattern\n",
        "    [0,1,2], # X pattern frame indices\n",
        "    [3,4,5]  # Y pattern frame indices\n",
        "])\n",
        "modulation_depth = 0.90\n",
        "modulation_angles_deg = [0, 90]\n",
        "pitch_nm = 220\n",
        "mod = angles_to_mod([pitch_nm, pitch_nm], pixelsize, modulation_angles_deg, modulation_depth, pattern_frames)\n",
        "mp_gt = pe.ModulationPattern(pattern_frames, mod)\n",
        "\n",
        "with Context() as ctx:\n",
        "  roisize = 10\n",
        "  psf = GaussianPSFMethods(ctx).CreatePSF_XYIBg(roisize, psf_calib, cuda=True)\n",
        "  mov = simulate(path, mp_gt, psf,\n",
        "      pts[:,:2], numframes=nframes, intensity=intensity, width=W,\n",
        "      bg=background, avg_on_time=avg_on_time, on_fraction=on_fraction, return_movie=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "9NHv6wLH31iF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the first few frames:\n",
        "frames = tiff_read_all(path, maxframes=6)\n",
        "fig,ax=plt.subplots(1,len(frames),figsize=(15,5))\n",
        "for i in range(len(frames)):\n",
        "    ax[i].imshow(frames[i])\n",
        "    ax[i].axis('off')\n",
        "    ax[i].set_aspect('equal')\n",
        "    ax[i].set_title(f'frame {i}')\n",
        "plt.tight_layout()\n",
        "plt.figure()\n",
        "plt.imshow(mov.mean(0)); plt.title('Measurement average')\n",
        "plt.axis('off')"
      ],
      "metadata": {
        "id": "VImjYBzDqklg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For comparison, we detect spots in a single emitter pipeline first, and run both SMLM and SIMFLUX fitters on the found ROIs\n",
        "\n",
        "# Change this when you're processing experimental data:\n",
        "camera_gain = 1\n",
        "camera_offset = 0\n",
        "\n",
        "localizer = SFLocalizer(path,\n",
        "   psf_calib = [psf_sigma, psf_sigma],\n",
        "   roisize = roisize,\n",
        "   detection_threshold = 5,\n",
        "   pattern_frames= pattern_frames,\n",
        "   gain = camera_gain,\n",
        "   offset = camera_offset,\n",
        "   pixelsize = pixelsize,\n",
        "   zrange = [0,0], # unsupported\n",
        "   psf_sigma_binsize = None, # if non-zero, it will estimate the PSF width over time with given bin size (in spot counts)\n",
        "   result_dir='results',\n",
        "   device='cuda:0')\n",
        "\n",
        "localizer.detect_spots(ignore_cache=False, moving_window=True)\n",
        "smlm_ds = localizer.fit_smlm(max_crlb_xy=None, ignore_cache=False)\n",
        "print(f\"numrois: {localizer.numrois}. #summed_fits: {localizer.summed_fits.shape[0]}, numframes: {smlm_ds.numFrames}\")\n"
      ],
      "metadata": {
        "id": "0nXdduiaydO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig,ax = plt.subplots(figsize=(8,8))\n",
        "smlm_ds.renderFigure(axes=ax,zoom=10,clip_percentile=98)"
      ],
      "metadata": {
        "id": "-KfZsnkayeLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Estimate patterns so we can run simflux fitting.\n",
        "# Note that in our method, optical setup modulation depths are highly underestimated in high density scenes,\n",
        "# so in practice we fix based on our estimates from low density measurements\n",
        "mp_est = localizer.estimate_angles(pitch_minmax_nm=[100,240])\n",
        "mp_est = localizer.estimate_phases(mp_est, spots_per_bin=5000,\n",
        "                                accept_percentile=40, iterations=10, verbose=False)\n",
        "mp_est.depths[:]=0.9\n",
        "# we also assume constant phase steps over time\n",
        "mp_est = mp_est.const_phase_offsets()\n"
      ],
      "metadata": {
        "id": "3C1aO1fZqS-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filter based on modulation error:\n",
        "# we calculate the expected intensities based on the SMLM position and our patterns, if too different then they are likely unreliable for a pattern based fit\n",
        "me = mp_est.mod_error(smlm_ds)\n",
        "me_sel = me < 0.1\n",
        "\n",
        "sf_ds = localizer.fit_simflux(mp_est, smlm_ds[me_sel], iterations=50, lambda_=500, ignore_cache=True, normalizeWeights=True, distFromSMLM=0.5)\n",
        "#lr.scatterplot([ sfloc.sum_ds, sf_ds ], connected=False, labels=['SMLM', 'SF'], limits=None, s=2)\n",
        "\n",
        "if False: #show intermediate results\n",
        "  fig,ax=plt.subplots(1,3,figsize=(15,5))\n",
        "  gt_ds.renderFigure(axes=ax[0],clip_percentile=90,zoom=10,title='Ground truth')\n",
        "  smlm_ds.renderFigure(axes=ax[1],zoom=10,clip_percentile=98,title='SMLM')\n",
        "  sf_ds.renderFigure(axes=ax[2],clip_percentile=98,zoom=10,title='SIMFLUX')\n"
      ],
      "metadata": {
        "id": "GhPLGI3-0JE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now run the simcode pipeline\n",
        "from smlmtorch.util.config_dict import config_dict # dictionary indexable like object\n",
        "from smlmtorch.nn.sf_model import SFLocalizationModel\n",
        "from smlmtorch.nn.localize_movie import MovieProcessor\n",
        "from smlmtorch.simflux.dataset import SFDataset\n",
        "import torch\n",
        "\n",
        "simcode_model_class = SFLocalizationModel\n",
        "\n",
        "config = config_dict.load(simcode_model_path + '/config.yaml')\n",
        "config = config_dict(**config, # Need to add some inference related parameters\n",
        "  detector=dict( prob_threshold=0.7, use_prob_weights=False )\n",
        ")\n",
        "config.model.num_intensities = pattern_frames.size\n",
        "\n",
        "mp = MovieProcessor(simcode_model_class, config, simcode_model_path+\"/checkpoint_1.pt\", device='cuda:0')\n",
        "# the model processes the data in batches of moving windows of frames [B, L, H, W], where L is the window size (6)\n",
        "simcode_nn_ds = mp.process(path, batch_size=32,\n",
        "                           batch_overlap = pattern_frames.size-1,\n",
        "                           gain = camera_gain,\n",
        "                           offset = camera_offset)\n",
        "simcode_nn_ds.crlb_filter(0.3) # reduce the size a bit, it generates a lot of low precision spots\n",
        "simcode_nn_ds['pixelsize'] = pixelsize\n",
        "\n",
        "# Saving in .npy will keep track of per-pattern spot intensities.\n",
        "simcode_nn_ds.save('/content/results/simcode-nn.npy')\n",
        "# Saving in hdf5 is Picasso compatible, but will lose per-pattern spot intensities,\n",
        "# and only store a single intensity per localization\n",
        "simcode_nn_ds.save('/content/results/simcode-nn.hdf5')\n"
      ],
      "metadata": {
        "id": "Vz4bllGB04WY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run pattern fits on NN outputs\n",
        "mp_sc = pe.estimate_angles(pitch_minmax_nm=[150,500], ds=simcode_nn_ds,\n",
        "                        pattern_frames = pattern_frames, result_dir = localizer.result_dir,\n",
        "                        device = localizer.device, moving_window = localizer.moving_window)\n",
        "\n",
        "mp_sc = pe.estimate_phases(simcode_nn_ds, mp_sc, spots_per_bin=10000,\n",
        "                        accept_percentile=50, iterations=1, verbose=False, device=localizer.device)\n",
        "mod_pattern_nn = mp_sc.const_phase_offsets()\n",
        "# Plot phases\n",
        "fig,ax=plt.subplots(2,1,figsize=(6,4))\n",
        "mp_sc.plot_phase_drift(nframes=10000,ax=ax, label='Pat {0}', linestyle='-', lw=1)\n"
      ],
      "metadata": {
        "id": "bzCM0AKYAZjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mod_error_threshold = 0.1\n",
        "print(f'computing modulation-enhanced positions using mod error threshold = {mod_error_threshold}')\n",
        "moderr_selected = mod_pattern_nn.mod_error(simcode_nn_ds) < mod_error_threshold\n",
        "\n",
        "ndi_input_ds = simcode_nn_ds[moderr_selected]\n",
        "simcode_pattern_fit_ds = pe.ndi_fit_dataset(ndi_input_ds, mod_pattern_nn, device=localizer.device)\n",
        "\n",
        "# Filter outliers based on the distance from the non pattern-fitted positions\n",
        "max_dist = 0.2\n",
        "dist = np.sqrt ( ( (simcode_pattern_fit_ds.pos[:,:2] - ndi_input_ds.pos[:,:2])**2 ).sum(1) )\n",
        "# Note that our Dataset class supports a mask indexing operation ds[boolean mask]\n",
        "simcode_pattern_fit_ds = simcode_pattern_fit_ds[dist<max_dist]\n",
        "simcode_pattern_fit_ds.save(localizer.result_dir + \"simcode-pattern-fitted.hdf5\")\n",
        "\n",
        "print(f'remaining after filtering by max distance from original: {len(simcode_pattern_fit_ds)}/{moderr_selected.sum()}')\n",
        "\n",
        "simcode_merged_ds = pe.merge_estimates(simcode_pattern_fit_ds, ndi_input_ds[dist<max_dist])\n",
        "simcode_merged_ds.save(\"/content/results/simcode.hdf5\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KcGxEwjdB4xn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig,ax=plt.subplots(3,2,figsize=(6,10))\n",
        "gt_ds.renderFigure(axes=ax[0,0],clip_percentile=90,zoom=10,title='Ground truth')\n",
        "ax[0,1].imshow(mov.mean(0)); ax[0,1].set_title('Measurement average')\n",
        "# disable axes\n",
        "ax[0,1].axis('off')\n",
        "smlm_ds.renderFigure(axes=ax[1,0],zoom=10,clip_percentile=98,title='SMLM')\n",
        "sf_ds.renderFigure(axes=ax[1,1],clip_percentile=98,zoom=10,title='SIMFLUX')\n",
        "\n",
        "# SIMCODE (Intermediate) here indicates the neural network output,\n",
        "# where localization is done by NN but a pattern based fit is not done yet.\n",
        "simcode_nn_ds.renderFigure(axes=ax[2,0],clip_percentile=98,zoom=10,title='SIMCODE (Int.)')\n",
        "ax[2,1].axis('off');\n",
        "simcode_merged_ds.renderFigure(axes=ax[2,1],clip_percentile=96,zoom=10,title='SIMCODE')\n",
        "#plt.tight_layout()"
      ],
      "metadata": {
        "id": "YUUSvXxJ7fm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = [smlm_ds, sf_ds, simcode_nn_ds, simcode_merged_ds]\n",
        "ds_labels = ['SMLM', 'SIMFLUX', 'SIMCODE (Int.)', 'SIMCODE']\n",
        "\n",
        "smooth_curve=16\n",
        "frcs = []\n",
        "\n",
        "for i in range(len(datasets)):\n",
        "  ds = datasets[i]\n",
        "  ds_label = ds_labels[i]\n",
        "  ds_frc = ds[ds.frame%6==0] # have statistically independent frames, cannot use overlapping sets of 6 frames.\n",
        "\n",
        "  frc_val, frc_curve, frc_freq = ds_frc.frc(display=False, zoom=20, smooth=smooth_curve, mask=None)\n",
        "  d = config_dict(frc=frc_val, curve=frc_curve, freq=frc_freq)\n",
        "  frcs.append(d)\n",
        "\n",
        "fig,ax=plt.subplots()\n",
        "crop_end = 100\n",
        "\n",
        "ax.axhline(1/7, color='grey', linestyle='--')\n",
        "for i in range(len(frcs)):\n",
        "  l=ax.plot(frcs[i].freq[:-crop_end], frcs[i].curve[:-crop_end], label=f'{ds_labels[i]} (FRC={frcs[i].frc:.1f} nm)')\n",
        "\n",
        "ax.legend(fontsize=13)\n",
        "ax.set_ylabel('FRC')\n",
        "ax.set_xlabel('Spatial freq. [nm^-1]')\n",
        "ax.set_title('Fourier ring correlation')\n",
        "\n"
      ],
      "metadata": {
        "id": "rsgRa6CWq8-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9_kEPQD9tJYy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}