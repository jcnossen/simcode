{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Clone and install the SIMCODE git repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CYERQ2RYogS"
      },
      "outputs": [],
      "source": [
        "# Clone the SIMCODE source code\n",
        "%cd /content\n",
        "!git clone https://github.com/jcnossen/simcode.git\n",
        "%cd /content/simcode/\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load all packages and configure the training object "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Dac3l7dYjNV"
      },
      "outputs": [],
      "source": [
        "import smlmtorch.util.progbar\n",
        "# set False if your jupyter notebook does not support javascript plugins\n",
        "smlmtorch.util.progbar.USE_AUTO_TQDM = False\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from smlmtorch import config_dict\n",
        "from smlmtorch.nn.sf_model import SFLocalizationModel\n",
        "from smlmtorch.nn.model_trainer import LocalizationModelTrainer\n",
        "from smlmtorch.nn.benchmark.compare_crlb import CRLBPlotGenerator\n",
        "\n",
        "bg_mean = 5 # for crlb plot\n",
        "device = 'cuda:0'\n",
        "moving_wnd_size = 6 # num intensities\n",
        "L = 64\n",
        "center_frame_ix = 2 # within moving window of 6\n",
        "gauss_sigma = 1.3\n",
        "\n",
        "# these are the configuration parameters for the model as used in the paper, most likely overkill though\n",
        "config = config_dict(\n",
        "    model = dict(\n",
        "        enable_readnoise = False,\n",
        "        enable3D = False,\n",
        "        unet_shared_features=[L, L*2], \n",
        "        unet_combiner_features=[L, L*2, L*4],\n",
        "        ie_input_features=32, # number of features going from combiner to IE\n",
        "        unet_batch_norm = True,\n",
        "        input_scale = 0.01, # get pixel values into useful range\n",
        "        input_offset = 3,\n",
        "        unet_combiner_output_features = 256,\n",
        "        output_head_features = 48,\n",
        "        num_intensities=moving_wnd_size,\n",
        "        max_bg=100,\n",
        "        max_intensity=20000,\n",
        "        xyz_scale=[1.1,1.1,1],\n",
        "        unet_intensity_features=[L, L*2, L*4],\n",
        "        output_intensity_features=32,\n",
        "        use_on_prob=False\n",
        "    ),\n",
        "    loss = dict(\n",
        "        gmm_components=0,\n",
        "        count_loss_weight=0.01,\n",
        "        track_intensities_offset = center_frame_ix\n",
        "    ),\n",
        "    optimizer_type = 'Lion',\n",
        "    optimizer = dict(\n",
        "        lr = 2e-5,\n",
        "        weight_decay = 0.01\n",
        "    ),\n",
        "    #clip_grad_norm_ = dict( max_norm=0.03, norm_type=2 ),\n",
        "    lr_scheduler = dict(step_size=30, gamma=0.5),\n",
        "    train_size = 8*1024,\n",
        "    test_size = 1024,\n",
        "    batch_size = 6,\n",
        "\n",
        "    simulation = dict(\n",
        "        num_frames = 32,\n",
        "        img_shape=(32,32),\n",
        "        z_range = (-0.5,0.5),\n",
        "        density_um2 = 1.5,\n",
        "        pixelsize_nm = 100,\n",
        "        mean_on_time = 6,\n",
        "        \n",
        "        track_intensities = moving_wnd_size,\n",
        "        track_intensities_offset = center_frame_ix,\n",
        "        intensity_distr = 'log-normal',\n",
        "        intensity_mode = 400,\n",
        "        intensity_mean = 600,\n",
        "        intensity_mean_min = 50,\n",
        "        intensity_mean_max = 10000,\n",
        "        intensity_fluctuation_std = 0.5, # I_frame = I_spot * (1 + fluctuation * randn())\n",
        "        bg_max = 20,\n",
        "        bg_min = 0.5,\n",
        "        render_args = dict(\n",
        "            read_noise_mean = 0.5,\n",
        "            read_noise_std = 1\n",
        "        ),\n",
        "        psf = dict(\n",
        "            type = 'Gaussian2D',\n",
        "            sigma = [gauss_sigma, gauss_sigma],\n",
        "        )\n",
        "    ),\n",
        "    benchmark = dict(\n",
        "        prob_threshold=0.5, \n",
        "        match_distance_px=3,\n",
        "        kdeplot_params =['N0', 'N5'],\n",
        "        render_frame_offset=center_frame_ix\n",
        "    )\n",
        ")\n",
        "\n",
        "# x,y,z,I,start,end,bg\n",
        "savedir = f'/content/models/sf_conv_g{gauss_sigma}_L{L}'\n",
        "\n",
        "trainer = LocalizationModelTrainer(config, SFLocalizationModel, device,\n",
        "    save_dir=savedir,\n",
        "    load_previous_model=True # find the latest checkpoint and continue from there\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Show the distribution of spot intensities in the training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRwOOmFXZyJS"
      },
      "outputs": [],
      "source": [
        "ds = trainer.data_generator.generate(100)\n",
        "active = ds.spots_ds.spots[:,:,:,0]>0\n",
        "intensities = ds.spots_ds.spots[:,:,:,1][active]\n",
        "\n",
        "plt.figure(figsize=(4,2))\n",
        "plt.hist(intensities, bins=100, range=[0,3000],density=True)\n",
        "plt.title('Histogram of spot intensities in training data')\n",
        "plt.ylabel('Intensity prob.density')\n",
        "plt.xlabel('Intensity [photons]')\n",
        "plt.savefig(trainer.save_dir+\"/intensities_histogram.svg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Run the training loop\n",
        "\n",
        "With current settings, the model should be ok after 100 epochs already. With current settings, the model should be ok after 80 epochs already. Note that you'll need at least the A100 runtime to do this in a reasonable time. Our model was trained on a standalone Ubuntu machine with an 3090 RTX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZ-F1mW3YjNa"
      },
      "outputs": [],
      "source": [
        "photon_range = np.logspace(2, 3.5, 10)\n",
        "\n",
        "crlb_plotter = CRLBPlotGenerator(trainer.model, 100,\n",
        "    trainer.data_generator.psf,\n",
        "    param_list=['N0', 'x', 'y'],\n",
        "    psf_param_mapping = ['N', 'x', 'y'],\n",
        "    sim_config=config.simulation, device=device)\n",
        "\n",
        "def plot_callback(epoch, batch, test_output):\n",
        "    # This allows us to see some intermediate results during training, in addition to the tensorboard logs\n",
        "    data, camera_calib, labels = batch\n",
        "    output = trainer.eval_batch(data[[0]], camera_calib[[0]])\n",
        "    y = trainer.model.to_global_coords(output, revert=True)\n",
        "\n",
        "    crlb_plotter.plot_photon_range(photon_range, background=bg_mean,\n",
        "        n_frames=moving_wnd_size, log_writer=trainer.writer, log_step=epoch)\n",
        "\n",
        "    mf = config.model.num_intensities\n",
        "    y = y[0,0]\n",
        "    fig, ax=plt.subplots(1,4)\n",
        "    ax[0].imshow(data[0,0].cpu().numpy()); ax[0].set_title('Input')\n",
        "    ax[1].imshow(y[0].cpu().numpy()); ax[1].set_title('p')\n",
        "    ax[2].imshow(y[1].cpu().numpy()); ax[2].set_title('x')\n",
        "    ax[3].imshow(y[2].cpu().numpy()); ax[3].set_title('y')\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "trainer.train(num_epochs=10, log_interval=1, batch_size = config['batch_size'],\n",
        "                data_refresh_interval=1, test_callback=plot_callback,\n",
        "                report_interval=1)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
